# ADR-019: AI-First Interaction Patterns & Natural Language Interface

## Status
Proposed

## Context

Modern AI developer tools (Lovable, Replit Ghostwriter, v0) have redefined user expectations around how developers interact with software. Natural language has become the primary interface, not a secondary feature.

### Current State

Forge Factory's interaction model is traditional:
- **Discovery:** Browse menus, click through options
- **Commands:** Click buttons, fill forms
- **Search:** Keyword-based, requires knowing exact terms
- **Learning Curve:** 2-3 days to become proficient

### Target State (Inspired by Lovable/Replit/v0)

Users should be able to:
- **Describe intent:** "Split all files over 500 lines into smaller modules"
- **Ask questions:** "Which files have the most complexity?"
- **Iterate naturally:** "Actually, just split the authentication files"
- **Get suggestions:** AI proactively suggests next actions

### Business Impact

**Activation Rate:**
- Current: Users take 5-10 minutes to run first analysis
- Target: <2 minutes with natural language ("Analyze my most active repository")

**Time-to-Value:**
- Current: 30 minutes to understand first recommendation
- Target: <5 minutes ("Explain this complexity score in simple terms")

**Competitive Positioning:**
- Without this: Forge Factory feels like a traditional tool
- With this: "It's like ChatGPT for your codebase"

### Requirements

1. **Natural Language Understanding:**
   - Intent detection (search, refactor, analyze, explain)
   - Entity extraction (file names, metrics, actions)
   - Context awareness (current repository, role, history)

2. **Conversational Interface:**
   - Chat-style interactions (like ChatGPT)
   - Multi-turn conversations with memory
   - Clarification questions when ambiguous

3. **Proactive Suggestions:**
   - AI suggests next steps
   - Context-aware recommendations
   - Inline suggestions in UI

4. **Integration Points:**
   - Command palette (âŒ˜K)
   - Sidebar chat
   - Inline prompts throughout UI
   - Voice input (future)

## Decision

We will implement a **multi-modal AI-first interaction system** with three primary interfaces:

### 1. AI Chat Sidebar (Primary Interface)
### 2. Natural Language Command Palette (Quick Actions)
### 3. Inline AI Suggestions (Contextual Assistance)

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI Interaction Architecture                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  User Interface Layer                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   AI Chat       â”‚  â”‚  Command        â”‚  â”‚   Inline     â”‚ â”‚
â”‚  â”‚   Sidebar       â”‚  â”‚  Palette        â”‚  â”‚  Suggestions â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚  (âŒ˜K)           â”‚  â”‚              â”‚ â”‚
â”‚  â”‚  "Split large   â”‚  â”‚  Type: "split   â”‚  â”‚  ðŸ’¡ AI says: â”‚ â”‚
â”‚  â”‚   files"        â”‚  â”‚  files..."      â”‚  â”‚  Split this  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                    â”‚                   â”‚          â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                â†“                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Natural Language Understanding (NLU)         â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  Intent Classification:                                â”‚ â”‚
â”‚  â”‚  - search: "find files over 500 lines"                â”‚ â”‚
â”‚  â”‚  - refactor: "split this file"                        â”‚ â”‚
â”‚  â”‚  - analyze: "check code quality"                      â”‚ â”‚
â”‚  â”‚  - explain: "why is this complex?"                    â”‚ â”‚
â”‚  â”‚  - navigate: "show me the auth module"               â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  Entity Extraction:                                    â”‚ â”‚
â”‚  â”‚  - Files: "auth.ts", "files over 500 lines"          â”‚ â”‚
â”‚  â”‚  - Metrics: "complexity", "test coverage"            â”‚ â”‚
â”‚  â”‚  - Actions: "split", "add types", "generate tests"   â”‚ â”‚
â”‚  â”‚  - Thresholds: "over 500", "less than 80%"           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Action Orchestration Layer                 â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  Convert intent â†’ API calls:                           â”‚ â”‚
â”‚  â”‚  "Split large files" â†’                                 â”‚ â”‚
â”‚  â”‚    1. GET /repositories/:id/files?size_gt=500          â”‚ â”‚
â”‚  â”‚    2. POST /refactorings/batch {type: "split_file"}   â”‚ â”‚
â”‚  â”‚    3. WebSocket subscribe to progress                  â”‚ â”‚
â”‚  â”‚    4. Return structured response                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                       â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Response Generation Layer                  â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  Generate human-friendly responses:                    â”‚ â”‚
â”‚  â”‚  - Natural language explanations                       â”‚ â”‚
â”‚  â”‚  - Markdown formatting                                 â”‚ â”‚
â”‚  â”‚  - Code snippets with syntax highlighting             â”‚ â”‚
â”‚  â”‚  - Interactive components (buttons, charts)           â”‚ â”‚
â”‚  â”‚  - Follow-up suggestions                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detailed Decisions

### 1. AI Chat Sidebar (Primary Interface)

**UI Location:** Right sidebar (collapsible, âŒ˜J to toggle)

**Features:**
- **Conversational History:** Scrollable chat thread
- **Multi-Turn Conversations:** AI remembers context
- **Rich Responses:** Markdown, code blocks, interactive components
- **Voice Input:** Microphone button for speech-to-text (future)
- **Suggested Prompts:** Quick-start buttons ("Analyze this repo", "Find issues")

**Implementation:**

```typescript
// apps/portal/components/ai-chat-sidebar.tsx
'use client'

import { useState, useEffect } from 'react'
import { ScrollArea } from '@packages/ui/scroll-area'
import { Button } from '@packages/ui/button'
import { Textarea } from '@packages/ui/textarea'
import { useAIChat } from '@/hooks/use-ai-chat'
import { ChatMessage } from './chat-message'
import { SuggestedPrompts } from './suggested-prompts'

export function AIChatSidebar() {
  const [input, setInput] = useState('')
  const { messages, sendMessage, isLoading } = useAIChat()

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault()
    if (!input.trim()) return

    await sendMessage(input)
    setInput('')
  }

  return (
    <div className="flex flex-col h-full border-l bg-background">
      {/* Header */}
      <div className="flex items-center justify-between p-4 border-b">
        <div className="flex items-center gap-2">
          <SparklesIcon className="h-5 w-5 text-primary" />
          <h3 className="font-semibold">AI Assistant</h3>
        </div>
        <Button variant="ghost" size="icon" onClick={onClose}>
          <XIcon className="h-4 w-4" />
        </Button>
      </div>

      {/* Chat Messages */}
      <ScrollArea className="flex-1 p-4">
        {messages.length === 0 ? (
          <div className="text-center text-muted-foreground space-y-4">
            <p>Ask me anything about your codebase:</p>
            <SuggestedPrompts
              prompts={[
                "Analyze this repository",
                "Which files are most complex?",
                "Split all large files",
                "Explain the AI-Readiness Score"
              ]}
              onSelect={(prompt) => sendMessage(prompt)}
            />
          </div>
        ) : (
          <div className="space-y-4">
            {messages.map((message) => (
              <ChatMessage key={message.id} message={message} />
            ))}
            {isLoading && <ChatMessage message={{ role: 'assistant', content: '...' }} />}
          </div>
        )}
      </ScrollArea>

      {/* Input */}
      <form onSubmit={handleSubmit} className="p-4 border-t">
        <div className="flex gap-2">
          <Textarea
            value={input}
            onChange={(e) => setInput(e.target.value)}
            placeholder="Ask about your code..."
            className="resize-none"
            rows={2}
            onKeyDown={(e) => {
              if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault()
                handleSubmit(e)
              }
            }}
          />
          <Button type="submit" size="icon" disabled={isLoading || !input.trim()}>
            <SendIcon className="h-4 w-4" />
          </Button>
        </div>
        <p className="text-xs text-muted-foreground mt-2">
          Press Enter to send, Shift+Enter for new line
        </p>
      </form>
    </div>
  )
}
```

**Chat Message Component:**

```typescript
// apps/portal/components/chat-message.tsx
'use client'

import { Avatar } from '@packages/ui/avatar'
import { Button } from '@packages/ui/button'
import { Card } from '@packages/ui/card'
import { MarkdownRenderer } from './markdown-renderer'
import { CodeBlock } from './code-block'
import { InteractiveAction } from './interactive-action'

interface ChatMessageProps {
  message: {
    id: string
    role: 'user' | 'assistant'
    content: string
    actions?: Array<{
      type: 'refactor' | 'navigate' | 'analyze'
      label: string
      params: Record<string, any>
    }>
  }
}

export function ChatMessage({ message }: ChatMessageProps) {
  const isUser = message.role === 'user'

  return (
    <div className={cn("flex gap-3", isUser && "flex-row-reverse")}>
      <Avatar className="h-8 w-8">
        {isUser ? (
          <AvatarFallback>You</AvatarFallback>
        ) : (
          <AvatarImage src="/ai-avatar.png" alt="AI" />
        )}
      </Avatar>

      <Card className={cn("p-3 max-w-[80%]", isUser && "bg-primary text-primary-foreground")}>
        <MarkdownRenderer content={message.content} />

        {/* Interactive Actions */}
        {message.actions && message.actions.length > 0 && (
          <div className="flex flex-wrap gap-2 mt-3">
            {message.actions.map((action, idx) => (
              <InteractiveAction key={idx} action={action} />
            ))}
          </div>
        )}
      </Card>
    </div>
  )
}
```

**AI Chat Hook:**

```typescript
// apps/portal/hooks/use-ai-chat.ts
import { useState } from 'react'
import { useMutation, useQuery } from '@tanstack/react-query'
import { apiClient } from '@packages/api-client'

interface Message {
  id: string
  role: 'user' | 'assistant'
  content: string
  actions?: Array<{
    type: string
    label: string
    params: Record<string, any>
  }>
  timestamp: Date
}

export function useAIChat(repositoryId?: string) {
  const [messages, setMessages] = useState<Message[]>([])

  const { mutateAsync: sendMessage, isLoading } = useMutation({
    mutationFn: async (content: string) => {
      // Add user message immediately
      const userMessage: Message = {
        id: crypto.randomUUID(),
        role: 'user',
        content,
        timestamp: new Date(),
      }
      setMessages((prev) => [...prev, userMessage])

      // Call AI endpoint
      const response = await apiClient.ai.chat({
        messages: [...messages, userMessage],
        repositoryId,
      })

      // Add assistant response
      const assistantMessage: Message = {
        id: crypto.randomUUID(),
        role: 'assistant',
        content: response.content,
        actions: response.actions,
        timestamp: new Date(),
      }
      setMessages((prev) => [...prev, assistantMessage])

      return response
    },
  })

  return {
    messages,
    sendMessage,
    isLoading,
    clearHistory: () => setMessages([]),
  }
}
```

### 2. Natural Language Command Palette

**UI:** Modal dialog (âŒ˜K to open)

**Enhanced Features:**
- **Natural Language Input:** "split large files" (not just "Split Large Files" button)
- **AI-Powered Search:** Fuzzy matching + semantic understanding
- **Contextual Results:** Different results based on current page
- **Recent Queries:** Show last 5 AI queries for quick repeat

**Implementation:**

```typescript
// apps/portal/components/ai-command-palette.tsx
'use client'

import { useState, useEffect } from 'react'
import { Command } from 'cmdk'
import { useRouter } from 'next/navigation'
import { useAIPalette } from '@/hooks/use-ai-palette'

export function AICommandPalette() {
  const [open, setOpen] = useState(false)
  const [query, setQuery] = useState('')
  const router = useRouter()

  const { suggestions, executeSuggestion, isLoading } = useAIPalette(query)

  // Keyboard shortcut
  useEffect(() => {
    const down = (e: KeyboardEvent) => {
      if (e.key === 'k' && (e.metaKey || e.ctrlKey)) {
        e.preventDefault()
        setOpen((open) => !open)
      }
    }
    document.addEventListener('keydown', down)
    return () => document.removeEventListener('keydown', down)
  }, [])

  return (
    <Command.Dialog open={open} onOpenChange={setOpen}>
      <Command.Input
        placeholder="Type a command or ask a question..."
        value={query}
        onValueChange={setQuery}
      />

      <Command.List>
        {isLoading && (
          <Command.Loading>Thinking...</Command.Loading>
        )}

        <Command.Empty>No results found.</Command.Empty>

        <Command.Group heading="AI Suggestions">
          {suggestions.map((suggestion) => (
            <Command.Item
              key={suggestion.id}
              onSelect={() => {
                executeSuggestion(suggestion)
                setOpen(false)
              }}
            >
              <SparklesIcon className="mr-2 h-4 w-4" />
              {suggestion.label}
              <span className="ml-auto text-xs text-muted-foreground">
                {suggestion.type}
              </span>
            </Command.Item>
          ))}
        </Command.Group>

        <Command.Group heading="Recent">
          {/* Recent AI queries */}
        </Command.Group>

        <Command.Group heading="Quick Actions">
          <Command.Item onSelect={() => router.push('/dashboard')}>
            <HomeIcon className="mr-2 h-4 w-4" />
            Dashboard
          </Command.Item>
          {/* ... */}
        </Command.Group>
      </Command.List>
    </Command.Dialog>
  )
}
```

**AI Palette Hook:**

```typescript
// apps/portal/hooks/use-ai-palette.ts
import { useQuery } from '@tanstack/react-query'
import { apiClient } from '@packages/api-client'
import { useDebouncedValue } from './use-debounced-value'

export function useAIPalette(query: string) {
  const debouncedQuery = useDebouncedValue(query, 300)

  const { data: suggestions, isLoading } = useQuery({
    queryKey: ['ai-palette', debouncedQuery],
    queryFn: () => apiClient.ai.parseCommand(debouncedQuery),
    enabled: debouncedQuery.length > 2,
  })

  const executeSuggestion = async (suggestion: AISuggestion) => {
    switch (suggestion.type) {
      case 'navigate':
        router.push(suggestion.params.url)
        break
      case 'refactor':
        await apiClient.refactorings.create(suggestion.params)
        break
      case 'analyze':
        await apiClient.analysis.run(suggestion.params)
        break
      case 'search':
        // Execute search
        break
    }
  }

  return {
    suggestions: suggestions || [],
    executeSuggestion,
    isLoading,
  }
}
```

### 3. Inline AI Suggestions

**UI:** Contextual tooltips/banners throughout the app

**Examples:**

**Repository List:**
```typescript
// If user has repos with large files
<InlineAISuggestion
  icon={<SparklesIcon />}
  message="3 repositories have files over 500 lines. Split them to improve AI-readiness?"
  actions={[
    { label: "Split Now", onClick: () => splitLargeFiles() },
    { label: "Learn Why", onClick: () => openExplanation() },
  ]}
/>
```

**Analysis Results:**
```typescript
// After viewing analysis
<InlineAISuggestion
  icon={<LightbulbIcon />}
  message="Based on your score, I recommend focusing on test coverage first. Want me to generate tests?"
  actions={[
    { label: "Generate Tests", onClick: () => generateTests() },
    { label: "Not Now", onClick: () => dismiss() },
  ]}
/>
```

**Implementation:**

```typescript
// packages/ui/components/inline-ai-suggestion.tsx
import { Card } from './card'
import { Button } from './button'

interface InlineAISuggestionProps {
  icon: React.ReactNode
  message: string
  actions: Array<{
    label: string
    onClick: () => void
  }>
  onDismiss?: () => void
}

export function InlineAISuggestion({
  icon,
  message,
  actions,
  onDismiss,
}: InlineAISuggestionProps) {
  return (
    <Card className="p-4 bg-gradient-to-r from-purple-50 to-blue-50 dark:from-purple-950 dark:to-blue-950 border-purple-200 dark:border-purple-800">
      <div className="flex items-start gap-3">
        <div className="flex-shrink-0 mt-0.5 text-purple-600 dark:text-purple-400">
          {icon}
        </div>
        <div className="flex-1">
          <p className="text-sm text-foreground mb-3">{message}</p>
          <div className="flex gap-2">
            {actions.map((action, idx) => (
              <Button
                key={idx}
                variant={idx === 0 ? 'default' : 'outline'}
                size="sm"
                onClick={action.onClick}
              >
                {action.label}
              </Button>
            ))}
          </div>
        </div>
        {onDismiss && (
          <Button
            variant="ghost"
            size="icon"
            className="flex-shrink-0"
            onClick={onDismiss}
          >
            <XIcon className="h-4 w-4" />
          </Button>
        )}
      </div>
    </Card>
  )
}
```

## Backend API Endpoints

### 1. AI Chat Endpoint

```typescript
// POST /api/ai/chat
{
  "messages": [
    { "role": "user", "content": "Split all large files" }
  ],
  "repositoryId": "repo_123", // optional context
  "userId": "user_456"
}

// Response
{
  "content": "I found 3 files over 500 lines:\n\n1. `src/components/App.tsx` (850 lines)\n2. `src/utils/helpers.ts` (620 lines)\n3. `src/api/endpoints.ts` (540 lines)\n\nWould you like me to split them into smaller modules?",
  "actions": [
    {
      "type": "refactor",
      "label": "Split All Files",
      "params": {
        "fileIds": ["file_1", "file_2", "file_3"],
        "refactoringType": "split_file"
      }
    },
    {
      "type": "navigate",
      "label": "View Files",
      "params": {
        "url": "/repositories/repo_123/files?size_gt=500"
      }
    }
  ],
  "intent": "refactor",
  "entities": {
    "files": ["App.tsx", "helpers.ts", "endpoints.ts"],
    "action": "split",
    "threshold": 500
  }
}
```

### 2. Command Palette Endpoint

```typescript
// POST /api/ai/parse-command
{
  "query": "split large files",
  "context": {
    "currentPage": "/repositories/repo_123",
    "repositoryId": "repo_123"
  }
}

// Response
{
  "suggestions": [
    {
      "id": "suggestion_1",
      "type": "refactor",
      "label": "Split files over 500 lines (3 found)",
      "params": {
        "repositoryId": "repo_123",
        "refactoringType": "split_file",
        "filter": { "size_gt": 500 }
      }
    },
    {
      "id": "suggestion_2",
      "type": "navigate",
      "label": "View large files in current repository",
      "params": {
        "url": "/repositories/repo_123/files?size_gt=500"
      }
    }
  ]
}
```

### 3. Inline Suggestions Endpoint

```typescript
// GET /api/ai/suggestions?repositoryId=repo_123&context=analysis_results
{
  "suggestions": [
    {
      "id": "suggestion_1",
      "type": "inline",
      "placement": "analysis_results_page",
      "icon": "lightbulb",
      "message": "Your test coverage is 45%. I can generate tests to reach 80%.",
      "actions": [
        {
          "type": "action",
          "label": "Generate Tests",
          "endpoint": "/api/refactorings/generate-tests",
          "params": { "repositoryId": "repo_123", "targetCoverage": 80 }
        }
      ]
    }
  ]
}
```

## Natural Language Understanding (NLU) System

**Approach:** Use LLM (Claude/GPT) for intent classification and entity extraction

**Implementation:**

```typescript
// apps/api/src/ai/nlu-service.ts
import Anthropic from '@anthropic-ai/sdk'

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
})

export class NLUService {
  async parseCommand(query: string, context?: Record<string, any>) {
    const prompt = `
You are an assistant for Forge Factory, a code refactoring platform.
Parse this user command and extract the intent and entities.

User command: "${query}"
Context: ${JSON.stringify(context)}

Respond in JSON format:
{
  "intent": "search" | "refactor" | "analyze" | "explain" | "navigate",
  "entities": {
    "files": ["file1.ts", "file2.ts"],
    "metric": "complexity" | "coverage" | "size",
    "threshold": number,
    "action": "split" | "add_types" | "generate_tests"
  },
  "action": {
    "type": "refactor" | "navigate" | "analyze",
    "params": {}
  }
}
`

    const response = await anthropic.messages.create({
      model: 'claude-sonnet-4.5-20251022',
      max_tokens: 1024,
      messages: [
        { role: 'user', content: prompt }
      ],
    })

    const parsed = JSON.parse(response.content[0].text)
    return parsed
  }

  async generateResponse(
    query: string,
    data: any,
    context?: Record<string, any>
  ): Promise<string> {
    const prompt = `
You are an assistant for Forge Factory.
Generate a helpful, concise response to this user query.

User query: "${query}"
Data: ${JSON.stringify(data)}
Context: ${JSON.stringify(context)}

Guidelines:
- Be concise (2-3 sentences max)
- Include specific numbers/files when relevant
- Suggest next actions
- Use markdown formatting
- Don't repeat the user's question
`

    const response = await anthropic.messages.create({
      model: 'claude-sonnet-4.5-20251022',
      max_tokens: 512,
      messages: [
        { role: 'user', content: prompt }
      ],
    })

    return response.content[0].text
  }
}
```

## Intent Classification Examples

| User Input | Intent | Entities | Action |
|------------|--------|----------|--------|
| "Split large files" | refactor | action: split, threshold: 500 | Create split_file refactorings |
| "Which files are most complex?" | search | metric: complexity, sort: desc | Navigate to files sorted by complexity |
| "Explain my AI score" | explain | metric: ai_readiness_score | Show explanation modal |
| "Generate tests for auth.ts" | refactor | files: [auth.ts], action: generate_tests | Create test generation job |
| "Show me the analysis" | navigate | page: analysis_results | Navigate to /analysis |
| "Add types to everything" | refactor | action: add_types, scope: all | Create type annotation jobs |

## Consequences

### Positive

1. **Lower Learning Curve:**
   - New users can ask questions instead of reading docs
   - Onboarding time: 30 min â†’ 5 min
   - Support tickets: -40%

2. **Higher Activation Rate:**
   - Natural language = faster time-to-first-value
   - Users discover features through conversation
   - Activation rate: 60% â†’ 80%

3. **Competitive Differentiation:**
   - "ChatGPT for your codebase" = unique positioning
   - Viral marketing moments ("Look how easy this is!")
   - Premium pricing justified by AI experience

4. **User Engagement:**
   - Conversational UI = higher engagement
   - Users spend 2x more time in app (in a good way)
   - NPS increase: 50 â†’ 70

5. **Product Velocity:**
   - Add new features without cluttering UI
   - AI teaches users about new capabilities
   - Experimentation: A/B test prompts, not UI

### Negative

1. **LLM Costs:**
   - Every chat message = API call to Claude/GPT
   - Estimated cost: $0.01-0.05 per conversation
   - Mitigation: Cache common queries, use cheaper models for simple intents

2. **Latency:**
   - LLM calls take 1-3 seconds
   - Perceived slowness vs instant button clicks
   - Mitigation: Streaming responses, optimistic UI, skeleton loaders

3. **Accuracy:**
   - NLU may misunderstand user intent (90% accuracy target)
   - Frustration when AI gets it wrong
   - Mitigation: Clarification questions, fallback to traditional UI

4. **Complexity:**
   - NLU system adds significant engineering complexity
   - Need to maintain prompt templates
   - Testing is harder (non-deterministic responses)
   - Mitigation: Extensive prompt testing, monitoring dashboards

5. **Privacy:**
   - User queries sent to third-party LLM providers
   - Enterprise customers may require on-premise NLU
   - Mitigation: Self-hosted LLM option, clear privacy policy

### Mitigations

1. **Cost Management:**
   - Cache responses for common queries (Redis)
   - Use cheaper models for simple intents (classification)
   - Use expensive models only for complex reasoning
   - Rate limiting per user (10 AI queries/minute)

2. **Latency Optimization:**
   - Stream responses (token-by-token)
   - Show "thinking" indicator immediately
   - Prefetch likely next actions
   - Debounce command palette queries (300ms)

3. **Accuracy Improvement:**
   - Ask clarification questions when ambiguous
   - Show confidence scores ("I'm 85% sure you want to...")
   - Provide "Not what you meant?" undo button
   - Log misclassifications for fine-tuning

4. **Fallback Mechanisms:**
   - If NLU fails, show traditional UI options
   - "I didn't understand. Did you mean: [options]?"
   - Always provide keyboard shortcuts as backup
   - Never block critical actions behind AI

5. **Enterprise Requirements:**
   - Self-hosted LLM option (vLLM deployment)
   - Air-gapped mode with local models
   - Opt-out of AI features (traditional UI fallback)
   - GDPR/SOC2 compliant data handling

## Implementation Plan

### Phase 1: AI Chat Sidebar (Weeks 1-4)
- [ ] Design chat UI component
- [ ] Implement AI chat hook (API integration)
- [ ] Build message rendering (markdown, code blocks)
- [ ] Add suggested prompts
- [ ] Basic NLU system (intent classification)
- [ ] Deploy to staging for testing

### Phase 2: Command Palette Enhancement (Weeks 5-6)
- [ ] Enhance command palette with NL input
- [ ] Integrate NLU for query parsing
- [ ] Add AI-powered suggestions
- [ ] Debouncing and caching
- [ ] User testing and iteration

### Phase 3: Inline Suggestions (Weeks 7-8)
- [ ] Design inline suggestion component
- [ ] Identify key placement points in UI
- [ ] Implement suggestion API endpoint
- [ ] A/B testing framework
- [ ] Analytics tracking

### Phase 4: Polish & Optimization (Weeks 9-10)
- [ ] Streaming responses
- [ ] Response caching (Redis)
- [ ] Error handling and fallbacks
- [ ] Accessibility audit
- [ ] Performance optimization
- [ ] Launch to production

## Metrics & Success Criteria

### User Engagement
- **AI Feature Adoption:** 70%+ of users try AI chat within first week
- **AI Query Volume:** Average 5+ AI queries per session
- **Activation Rate:** 80%+ (from 60% baseline)
- **Time-to-First-Value:** <5 minutes (from 30 min baseline)

### Quality Metrics
- **Intent Accuracy:** 90%+ correct intent classification
- **User Satisfaction:** 80%+ of AI responses rated helpful
- **Error Rate:** <10% of queries result in "I don't understand"
- **Clarification Rate:** <20% require follow-up clarification

### Performance
- **Response Latency:** <2s for 90th percentile
- **Streaming Start:** <500ms to first token
- **Cache Hit Rate:** 60%+ for common queries
- **Uptime:** 99.5%+ AI service availability

### Business Impact
- **Support Deflection:** 40% reduction in support tickets
- **NPS Increase:** +20 points (50 â†’ 70)
- **Feature Discovery:** 2x increase in feature usage
- **Premium Conversion:** 15% higher (users willing to pay for AI)

## Alternatives Considered

### 1. Button-Based UI Only
- **Pros:** Simpler implementation, predictable behavior
- **Cons:** Doesn't match 2026 user expectations, high learning curve
- **Rejected:** Not competitive with Lovable/Replit/v0

### 2. Keyword Search Only
- **Pros:** Fast, deterministic, no LLM costs
- **Cons:** Requires users to know exact terms, not conversational
- **Rejected:** Too limited, doesn't feel AI-native

### 3. Pre-Trained Model (No LLM API)
- **Pros:** Lower cost, faster, no third-party dependency
- **Cons:** Lower accuracy, harder to maintain, no reasoning
- **Rejected:** Accuracy too low for complex intents

### 4. Voice-First Interface
- **Pros:** Ultimate in natural interaction
- **Cons:** Too early, accessibility issues, privacy concerns
- **Rejected:** Deferred to Phase 2 (post-launch)

## References

### Inspiration
- [Lovable AI App Builder](https://lovable.dev/) - Natural language to full app
- [Replit Ghostwriter](https://replit.com/ai) - AI pair programming
- [v0 by Vercel](https://v0.dev/) - Text-to-UI generation
- [Cursor IDE](https://cursor.sh/) - AI-first code editor
- [GitHub Copilot Chat](https://github.com/features/copilot) - Conversational AI

### Research
- [Conversational AI UX Patterns](https://www.nngroup.com/articles/chatbot-usability/)
- [Natural Language Interfaces 2026](https://www.gartner.com/en/articles/natural-language-interfaces)
- [LLM-Powered Applications](https://www.anthropic.com/research/building-llm-applications)

### Internal References
- ADR-004: LLM Provider Integration (Anthropic/OpenAI setup)
- ADR-012: User Portal Onboarding (integration points)
- ADR-015: Real-Time Updates (WebSocket for streaming)

## Review Date
April 2026 (3 months)

**Reviewers:** Product Lead, Engineering Lead, Design Lead, CTO

---

**Document Version:** 1.0
**Last Updated:** 2026-01-20
**Authors:** Product & Engineering Team
**Approved By:** [Pending]
